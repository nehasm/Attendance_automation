{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Edge Detection\n"
     ]
    }
   ],
   "source": [
    "import cv2 #import the library\n",
    "import imutils\n",
    "image = cv2.imread(\"input.jpg\")#read the image\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)#resizing image and change height to 500\n",
    " \n",
    "# convert the image to grayscale, blur it, and find edges in the image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    " \n",
    "# show the original image and the edge detected image\n",
    "print(\"STEP 1: Edge Detection\")\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Find contours of paper\n"
     ]
    }
   ],
   "source": [
    "# find the contours in the edged image, keeping only the largest ones, and initialize the screen contour\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    " \n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "     # approximate the contour\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    " \n",
    "    # if our approximated contour has four points, then we\n",
    "    # can assume that we have found our screen\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "#sort the contour,drawing the contour on image\n",
    "print(\"STEP 2: Find contours of paper\")\n",
    "cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#from the above code we extracted the table from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Apply perspective transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scanning the image to remove the noise\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    " \n",
    "# convert the warped image to grayscale\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# show the original and scanned images\n",
    "print(\"STEP 3: Apply perspective transform\")\n",
    "# cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "cv2.imwrite(\"Scanned.jpg\", imutils.resize(warped, height = 650,width=420))\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(651, 420, 3)\n"
     ]
    }
   ],
   "source": [
    "n=cv2.imread(\"Scanned.jpg\")\n",
    "print(n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to crop every horizontal row from image and save it\n",
    "def clip(a):\n",
    "    idx=0\n",
    "    cropped_dir_path=\"E:/Users/NM/envs/cv/ocraa/fa/a\"\n",
    "    for i in range(21):        \n",
    "            i=a[:31,:]\n",
    "            cv2.imwrite(cropped_dir_path+str(idx) + '.png',i)  \n",
    "            idx+=1\n",
    "            a=a[31:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the small rectangle block from the horizontal cropped row\n",
    "def v_clip(a):\n",
    "    idx=0\n",
    "    for i in range(7):        \n",
    "            i=a[:,:60]\n",
    "#             print(i.shape)\n",
    "            cv2.imwrite(cropped_dir_path+str(idx) + '.png',i)  \n",
    "            idx+=1\n",
    "            a=a[:,60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over all the horizontal cropped image and extracting the small rectangle\n",
    "for i in range(21):\n",
    "    j=str(i)\n",
    "    path=\"E:/Users/NM/envs/cv/ocraa/fa/a\"\n",
    "    ver=cv2.imread(path+j+\".png\")\n",
    "    cropped_dir_path=\"E:/Users/NM/envs/cv/ocraa/fa/A0/b\"+str(i)\n",
    "    v_clip(ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading every small rectangle,listing the rgb value of block and then flating three value to get the single value through pix_val_flat\n",
    "from PIL import Image\n",
    "small_part_path = \"E:/Users/NM/envs/cv/ocraa/faltu/A0/b\"\n",
    "l=[]\n",
    "for i in range(1,21):\n",
    "    b=str(i)\n",
    "    for j in range(1,7):\n",
    "        im=Image.open(small_part_path+b+str(j)+\".png\",\"r\")\n",
    "        pix_val = list(im.getdata())\n",
    "        pix_val_flat = [x for sets in pix_val for x in sets]\n",
    "        value=0\n",
    "        #after getting pixels value of image,adding all the value \n",
    "        for i in pix_val_flat:\n",
    "             value+=i     \n",
    "        #after addition,with checking and comparing the value,we can get whether it is black block or white block        \n",
    "        if value>550000:\n",
    "            l.append(\"A\")#adding P or A to list based on the magnitude of value.\n",
    "# #             print(\"A\"+b)\n",
    "        else:\n",
    "#             print(\"P\"+b+)\n",
    "            l.append(\"P\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['P', 'A', 'P', 'A', 'A', 'P'], ['A', 'P', 'A', 'P', 'A', 'A'], ['A', 'A', 'P', 'A', 'A', 'A'], ['P', 'A', 'A', 'A', 'A', 'A'], ['A', 'A', 'P', 'A', 'A', 'A'], ['A', 'P', 'A', 'A', 'P', 'A'], ['P', 'A', 'P', 'A', 'A', 'P'], ['A', 'P', 'A', 'P', 'A', 'P'], ['P', 'A', 'P', 'A', 'P', 'A'], ['A', 'P', 'A', 'P', 'A', 'P'], ['P', 'A', 'P', 'A', 'P', 'A'], ['A', 'P', 'A', 'P', 'A', 'P'], ['P', 'P', 'P', 'A', 'P', 'A'], ['P', 'A', 'P', 'P', 'A', 'P'], ['A', 'P', 'A', 'P', 'A', 'A'], ['P', 'A', 'P', 'A', 'P', 'A'], ['A', 'P', 'P', 'A', 'P', 'A'], ['P', 'P', 'A', 'P', 'A', 'P'], ['A', 'P', 'A', 'P', 'A', 'P'], ['P', 'A', 'P', 'A', 'P', 'A']]\n"
     ]
    }
   ],
   "source": [
    "#making the small list of 6 entries inside the main list\n",
    "n=6\n",
    "final = [l[i * n:(i + 1) * n] for i in range((len(l) + n - 1) // n )]\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['P', 'A', 'P', 'A', 'A', 'P'], 2: ['A', 'P', 'A', 'P', 'A', 'A'], 3: ['A', 'A', 'P', 'A', 'A', 'A'], 4: ['P', 'A', 'A', 'A', 'A', 'A'], 5: ['A', 'A', 'P', 'A', 'A', 'A'], 6: ['A', 'P', 'A', 'A', 'P', 'A'], 7: ['P', 'A', 'P', 'A', 'A', 'P'], 8: ['A', 'P', 'A', 'P', 'A', 'P'], 9: ['P', 'A', 'P', 'A', 'P', 'A'], 10: ['A', 'P', 'A', 'P', 'A', 'P'], 11: ['P', 'A', 'P', 'A', 'P', 'A'], 12: ['A', 'P', 'A', 'P', 'A', 'P'], 13: ['P', 'P', 'P', 'A', 'P', 'A'], 14: ['P', 'A', 'P', 'P', 'A', 'P'], 15: ['A', 'P', 'A', 'P', 'A', 'A'], 16: ['P', 'A', 'P', 'A', 'P', 'A'], 17: ['A', 'P', 'P', 'A', 'P', 'A'], 18: ['P', 'P', 'A', 'P', 'A', 'P'], 19: ['A', 'P', 'A', 'P', 'A', 'P'], 20: ['P', 'A', 'P', 'A', 'P', 'A']}\n"
     ]
    }
   ],
   "source": [
    "#assigning the respective number to the small list and structuring it like the image after classification\n",
    "dict={}\n",
    "for i in range(1,21):\n",
    "    dict[i]=final[i-1]\n",
    "print(dict)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
